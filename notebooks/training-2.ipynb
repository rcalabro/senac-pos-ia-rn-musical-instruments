{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e95b9cbc",
   "metadata": {},
   "source": [
    "# Traning - Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d029b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: absl-py==2.2.2 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 1)) (2.2.2)\n",
      "Requirement already satisfied: asttokens==3.0.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 3)) (1.6.3)\n",
      "Requirement already satisfied: audioread==3.0.1 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 4)) (3.0.1)\n",
      "Requirement already satisfied: certifi==2025.1.31 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 5)) (2025.1.31)\n",
      "Requirement already satisfied: cffi==1.17.1 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 6)) (1.17.1)\n",
      "Requirement already satisfied: charset-normalizer==3.4.1 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 7)) (3.4.1)\n",
      "Requirement already satisfied: comm==0.2.2 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 8)) (0.2.2)\n",
      "Requirement already satisfied: contourpy==1.3.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 9)) (1.3.0)\n",
      "Requirement already satisfied: cycler==0.12.1 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 10)) (0.12.1)\n",
      "Requirement already satisfied: debugpy==1.8.14 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 11)) (1.8.14)\n",
      "Requirement already satisfied: decorator==5.2.1 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 12)) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup==1.2.2 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 13)) (1.2.2)\n",
      "Requirement already satisfied: executing==2.2.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 14)) (2.2.0)\n",
      "Requirement already satisfied: flatbuffers==25.2.10 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 15)) (25.2.10)\n",
      "Requirement already satisfied: fonttools==4.57.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 16)) (4.57.0)\n",
      "Requirement already satisfied: gast==0.6.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 17)) (0.6.0)\n",
      "Requirement already satisfied: google-pasta==0.2.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 18)) (0.2.0)\n",
      "Requirement already satisfied: graphviz==0.20.3 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 19)) (0.20.3)\n",
      "Requirement already satisfied: grpcio==1.71.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 20)) (1.71.0)\n",
      "Requirement already satisfied: h5py==3.13.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 21)) (3.13.0)\n",
      "Requirement already satisfied: idna==3.10 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 22)) (3.10)\n",
      "Requirement already satisfied: importlib_metadata==8.6.1 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 23)) (8.6.1)\n",
      "Requirement already satisfied: importlib_resources==6.5.2 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 24)) (6.5.2)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 25)) (6.29.5)\n",
      "Requirement already satisfied: ipython==8.18.1 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 26)) (8.18.1)\n",
      "Requirement already satisfied: jedi==0.19.2 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 27)) (0.19.2)\n",
      "Requirement already satisfied: joblib==1.4.2 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 28)) (1.4.2)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 29)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 30)) (5.7.2)\n",
      "Requirement already satisfied: kagglehub==0.3.11 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 31)) (0.3.11)\n",
      "Requirement already satisfied: keras==3.9.2 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 32)) (3.9.2)\n",
      "Requirement already satisfied: kiwisolver==1.4.7 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 33)) (1.4.7)\n",
      "Requirement already satisfied: lazy_loader==0.4 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 34)) (0.4)\n",
      "Requirement already satisfied: libclang==18.1.1 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 35)) (18.1.1)\n",
      "Requirement already satisfied: librosa==0.11.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 36)) (0.11.0)\n",
      "Requirement already satisfied: llvmlite==0.43.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 37)) (0.43.0)\n",
      "Requirement already satisfied: Markdown==3.8 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 38)) (3.8)\n",
      "Requirement already satisfied: markdown-it-py==3.0.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 39)) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe==3.0.2 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 40)) (3.0.2)\n",
      "Requirement already satisfied: matplotlib==3.9.4 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 41)) (3.9.4)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 42)) (0.1.7)\n",
      "Requirement already satisfied: mdurl==0.1.2 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 43)) (0.1.2)\n",
      "Requirement already satisfied: ml_dtypes==0.5.1 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 44)) (0.5.1)\n",
      "Requirement already satisfied: msgpack==1.1.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 45)) (1.1.0)\n",
      "Requirement already satisfied: namex==0.0.8 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 46)) (0.0.8)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 47)) (1.6.0)\n",
      "Requirement already satisfied: numba==0.60.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 48)) (0.60.0)\n",
      "Requirement already satisfied: numpy==2.0.2 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 49)) (2.0.2)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.5.3.2 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 50)) (12.5.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.5.82 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 51)) (12.5.82)\n",
      "Requirement already satisfied: nvidia-cuda-nvcc-cu12==12.5.82 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 52)) (12.5.82)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.5.82 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 53)) (12.5.82)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.5.82 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 54)) (12.5.82)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.3.0.75 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 55)) (9.3.0.75)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.3.61 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 56)) (11.2.3.61)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.6.82 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 57)) (10.3.6.82)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.3.83 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 58)) (11.6.3.83)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.1.3 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 59)) (12.5.1.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.23.4 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 60)) (2.23.4)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.5.82 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 61)) (12.5.82)\n",
      "Requirement already satisfied: opencv-python==4.11.0.86 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 62)) (4.11.0.86)\n",
      "Requirement already satisfied: opt_einsum==3.4.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 63)) (3.4.0)\n",
      "Requirement already satisfied: optree==0.15.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 64)) (0.15.0)\n",
      "Requirement already satisfied: packaging==24.2 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 65)) (24.2)\n",
      "Requirement already satisfied: pandas==2.2.3 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 66)) (2.2.3)\n",
      "Requirement already satisfied: parso==0.8.4 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 67)) (0.8.4)\n",
      "Requirement already satisfied: pexpect==4.9.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 68)) (4.9.0)\n",
      "Requirement already satisfied: pillow==11.2.1 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 69)) (11.2.1)\n",
      "Requirement already satisfied: platformdirs==4.3.7 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 70)) (4.3.7)\n",
      "Requirement already satisfied: pooch==1.8.2 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 71)) (1.8.2)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.51 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 72)) (3.0.51)\n",
      "Requirement already satisfied: protobuf==5.29.4 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 73)) (5.29.4)\n",
      "Requirement already satisfied: psutil==7.0.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 74)) (7.0.0)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 75)) (0.7.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 76)) (0.2.3)\n",
      "Requirement already satisfied: pycparser==2.22 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 77)) (2.22)\n",
      "Requirement already satisfied: pydot==3.0.4 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 78)) (3.0.4)\n",
      "Requirement already satisfied: Pygments==2.19.1 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 79)) (2.19.1)\n",
      "Requirement already satisfied: pyparsing==3.2.3 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 80)) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 81)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz==2025.2 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 82)) (2025.2)\n",
      "Requirement already satisfied: PyYAML==6.0.2 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 83)) (6.0.2)\n",
      "Requirement already satisfied: pyzmq==26.4.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 84)) (26.4.0)\n",
      "Requirement already satisfied: requests==2.32.3 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 85)) (2.32.3)\n",
      "Requirement already satisfied: rich==14.0.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 86)) (14.0.0)\n",
      "Requirement already satisfied: scikit-learn==1.6.1 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 87)) (1.6.1)\n",
      "Requirement already satisfied: scipy==1.13.1 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 88)) (1.13.1)\n",
      "Requirement already satisfied: six==1.17.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 89)) (1.17.0)\n",
      "Requirement already satisfied: soundfile==0.13.1 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 90)) (0.13.1)\n",
      "Requirement already satisfied: soxr==0.5.0.post1 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 91)) (0.5.0.post1)\n",
      "Requirement already satisfied: stack-data==0.6.3 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 92)) (0.6.3)\n",
      "Requirement already satisfied: tensorboard==2.19.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 93)) (2.19.0)\n",
      "Requirement already satisfied: tensorboard-data-server==0.7.2 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 94)) (0.7.2)\n",
      "Requirement already satisfied: tensorflow==2.19.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 95)) (2.19.0)\n",
      "Requirement already satisfied: tensorflow-addons==0.23.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 96)) (0.23.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 97)) (0.37.1)\n",
      "Requirement already satisfied: termcolor==3.0.1 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 98)) (3.0.1)\n",
      "Requirement already satisfied: threadpoolctl==3.6.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 99)) (3.6.0)\n",
      "Requirement already satisfied: tornado==6.4.2 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 100)) (6.4.2)\n",
      "Requirement already satisfied: tqdm==4.67.1 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 101)) (4.67.1)\n",
      "Requirement already satisfied: traitlets==5.14.3 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 102)) (5.14.3)\n",
      "Requirement already satisfied: typeguard==2.13.3 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 103)) (2.13.3)\n",
      "Requirement already satisfied: typing_extensions==4.13.2 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 104)) (4.13.2)\n",
      "Requirement already satisfied: tzdata==2025.2 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 105)) (2025.2)\n",
      "Requirement already satisfied: urllib3==2.4.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 106)) (2.4.0)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 107)) (0.2.13)\n",
      "Requirement already satisfied: Werkzeug==3.1.3 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 108)) (3.1.3)\n",
      "Requirement already satisfied: wrapt==1.17.2 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 109)) (1.17.2)\n",
      "Requirement already satisfied: zipp==3.21.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from -r ../requirements.txt (line 110)) (3.21.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from astunparse==1.6.3->-r ../requirements.txt (line 3)) (0.45.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages (from tensorboard==2.19.0->-r ../requirements.txt (line 93)) (58.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 25.1 is available.\n",
      "You should consider upgrading via the '/home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc395302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.19.0\n",
      "Keras: 3.9.2\n",
      "Is TensorFlow using GPU? True\n",
      "GPU disponível: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "XLA ativado: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745958950.269023  129308 gpu_device.cc:2019] Created device /device:GPU:0 with 4047 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:0a:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "os.environ['ABSL_LOG_THRESHOLD'] = '0'\n",
    "\n",
    "# Built-in\n",
    "import ast\n",
    "import json\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party - Data Handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Third-party - Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Third-party - Machine Learning\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Third-party - Deep Learning\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Third-party - Audio Processing\n",
    "import librosa\n",
    "from librosa.feature.rhythm import tempo\n",
    "import soundfile as sf\n",
    "\n",
    "# Third-party - Utilities\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"Keras:\", keras.__version__)\n",
    "print(\"Is TensorFlow using GPU?\", tf.test.is_gpu_available())\n",
    "print(\"GPU disponível:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"XLA ativado:\", tf.config.optimizer.get_jit())\n",
    "# Mostra configuração geral\n",
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07406475",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGIN_DATASET_PATH = '../datasets/augmented'\n",
    "ORIGIN_DATASET_VERSION = 'v2'\n",
    "\n",
    "ORIGIN_DATASET_VERSION_PATH = Path(os.path.join(ORIGIN_DATASET_PATH, ORIGIN_DATASET_VERSION))\n",
    "ORIGIN_DATASET_TRAIN_METADATA = ORIGIN_DATASET_VERSION_PATH / 'train_metadata.csv'\n",
    "ORIGIN_DATASET_TRAIN_DATA = ORIGIN_DATASET_VERSION_PATH / 'train_data'\n",
    "\n",
    "ORIGIN_DATASET_TEST_METADATA = ORIGIN_DATASET_VERSION_PATH / 'test_metadata.csv'\n",
    "ORIGIN_DATASET_TEST_DATA = ORIGIN_DATASET_VERSION_PATH / 'test_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5fc27e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 TRAINING_DATASET_VERSION_PATH: ../datasets/training/v7\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DATASET_PATH = '../datasets/training'\n",
    "TRAINING_DATASET_VERSION = 'v7'\n",
    "\n",
    "TRAINING_DATASET_VERSION_PATH = Path(os.path.join(TRAINING_DATASET_PATH, TRAINING_DATASET_VERSION))\n",
    "\n",
    "TRAINING_DATASET_TRAIN_METADATA = TRAINING_DATASET_VERSION_PATH / 'train_metadata.csv'\n",
    "TRAINING_DATASET_TEST_METADATA = TRAINING_DATASET_VERSION_PATH / 'test_metadata.csv'\n",
    "\n",
    "TRAINING_DATASET_VERSION_PATH.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"📁 TRAINING_DATASET_VERSION_PATH: {TRAINING_DATASET_VERSION_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320d6cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_features(row, basepath, n_mfcc=40):\n",
    "    filepath = basepath / row['filename']\n",
    "    y, sr = librosa.load(filepath, sr=None, res_type='kaiser_fast')\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc).mean(axis=1)\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr).mean(axis=1)\n",
    "    contrast = librosa.feature.spectral_contrast(y=y, sr=sr).mean(axis=1)\n",
    "    features = np.concatenate([mfcc, chroma, contrast], axis=0)\n",
    "    features = (features - np.mean(features)) / np.std(features)\n",
    "\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b746d8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_dataset(metadata_file, output_metadata, input_audio_dir=None, n_mfcc=80):\n",
    "    metadata_file = Path(metadata_file)\n",
    "    output_metadata = Path(output_metadata)\n",
    "    input_audio_dir = Path(input_audio_dir) if input_audio_dir else metadata_file.parent\n",
    "\n",
    "    df = pd.read_csv(metadata_file nrows=10)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['label'] = label_encoder.fit_transform(df['class'])\n",
    "\n",
    "    tqdm.pandas(desc=\"Extraindo features\")\n",
    "    df['features'] = df.progress_apply(lambda row: extract_features(row, input_audio_dir, n_mfcc).mean(axis=0).tolist(), axis=1)\n",
    "\n",
    "    df[['class', 'features', 'label']].to_csv(output_metadata, index=False)\n",
    "    print(f\"✅ Dataset com features salvo em: {output_metadata}\")\n",
    "    return label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bbeb779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraindo features:   1%|          | 109/15774 [00:07<44:31,  5.86it/s]/home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages/librosa/core/pitch.py:103: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n",
      "Extraindo features: 100%|██████████| 15774/15774 [25:00<00:00, 10.51it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset com features salvo em: ../datasets/training/v7/train_metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "label_encoder = prepare_dataset(\n",
    "    metadata_file=ORIGIN_DATASET_TRAIN_METADATA,\n",
    "    input_audio_dir=ORIGIN_DATASET_TRAIN_DATA,\n",
    "    output_metadata=TRAINING_DATASET_TRAIN_METADATA,\n",
    "    n_mfcc=80\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a94b114",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string: 0.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X, y, label_encoder, ds_shape\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Uso:\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m X, y, label_encoder, ds_shape \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_from_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRAINING_DATASET_TRAIN_METADATA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(ds_shape)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# 🔥 Split normal\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m, in \u001b[0;36mload_dataset_from_csv\u001b[0;34m(csv_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_dataset_from_csv\u001b[39m(csv_path):\n\u001b[1;32m      2\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_path)\n\u001b[0;32m----> 4\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeatures\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mliteral_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      8\u001b[0m     label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n",
      "File \u001b[0;32m~/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages/pandas/core/series.py:4917\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/codebase/senac-ia/neural-networks/rn-musical-instruments/.venv/lib/python3.9/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.asdf/installs/python/3.9.16/lib/python3.9/ast.py:105\u001b[0m, in \u001b[0;36mliteral_eval\u001b[0;34m(node_or_string)\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_signed_num(node)\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_or_string\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.asdf/installs/python/3.9.16/lib/python3.9/ast.py:104\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_signed_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.asdf/installs/python/3.9.16/lib/python3.9/ast.py:78\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_signed_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m operand\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.asdf/installs/python/3.9.16/lib/python3.9/ast.py:69\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_convert_num\u001b[39m(node):\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, Constant) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(node\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mcomplex\u001b[39m):\n\u001b[0;32m---> 69\u001b[0m         \u001b[43m_raise_malformed_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m~/.asdf/installs/python/3.9.16/lib/python3.9/ast.py:66\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._raise_malformed_node\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_raise_malformed_node\u001b[39m(node):\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmalformed node or string: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: malformed node or string: 0.0"
     ]
    }
   ],
   "source": [
    "def load_dataset_from_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    df['features'] = df['features'].apply(ast.literal_eval)\n",
    "\n",
    "    X = np.vstack(df['features'].values).astype(np.float32)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(df['class'].values)\n",
    "\n",
    "    ds_shape = (X.shape[1],)\n",
    "\n",
    "    return X, y, label_encoder, ds_shape\n",
    "\n",
    "# Uso:\n",
    "X, y, label_encoder, ds_shape = load_dataset_from_csv(TRAINING_DATASET_TRAIN_METADATA)\n",
    "\n",
    "print(ds_shape)\n",
    "\n",
    "# 🔥 Split normal\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb158e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_robust_dense_model(input_shape, num_classes, gamma=1.0, alpha=0.25):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.BatchNormalization()(inputs)\n",
    "\n",
    "    x = layers.Dense(512, activation='swish', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "\n",
    "    x1 = layers.Dense(256, activation='swish', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x1 = layers.BatchNormalization()(x1)\n",
    "    x1 = layers.Dropout(0.3)(x1)\n",
    "\n",
    "    x2 = layers.Dense(256, activation='swish', kernel_regularizer=regularizers.l2(1e-4))(x1)\n",
    "    x2 = layers.BatchNormalization()(x2)\n",
    "    x2 = layers.Dropout(0.3)(x2)\n",
    "\n",
    "    x = layers.add([x1, x2])\n",
    "\n",
    "    x3 = layers.Dense(128, activation='swish', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x3 = layers.BatchNormalization()(x3)\n",
    "    x3 = layers.Dropout(0.25)(x3)\n",
    "\n",
    "    x4 = layers.Dense(128, activation='swish', kernel_regularizer=regularizers.l2(1e-4))(x3)\n",
    "    x4 = layers.BatchNormalization()(x4)\n",
    "    x4 = layers.Dropout(0.25)(x4)\n",
    "\n",
    "    x = layers.add([x3, x4])\n",
    "\n",
    "    x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "    def focal_loss(gamma=2., alpha=0.25):\n",
    "        def loss(y_true, y_pred):\n",
    "            y_true = tf.cast(y_true, tf.int32)\n",
    "            y_true_one_hot = tf.one_hot(y_true, depth=tf.shape(y_pred)[-1])\n",
    "            cross_entropy = K.categorical_crossentropy(y_true_one_hot, y_pred)\n",
    "            pt = tf.reduce_sum(y_true_one_hot * y_pred, axis=-1)\n",
    "            fl = alpha * tf.pow(1. - pt, gamma) * cross_entropy\n",
    "            return fl\n",
    "        return loss\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=focal_loss(gamma=gamma, alpha=alpha),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5ddf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image, display\n",
    "\n",
    "model = build_robust_dense_model(\n",
    "    input_shape=(160,),\n",
    "    num_classes=len(label_encoder.classes_)\n",
    ")\n",
    "\n",
    "plot_model(\n",
    "    model,\n",
    "    to_file='model_plot.png',\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    expand_nested=True,\n",
    "    dpi=96\n",
    ")\n",
    "\n",
    "# Exibe no notebook\n",
    "display(Image(filename='model_plot.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e53a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_robust_dense_model(\n",
    "    input_shape=(160,),\n",
    "    num_classes=len(label_encoder.classes_),\n",
    "    gamma=1.5,\n",
    "    alpha=0.3,\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=15, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(factor=0.5, patience=10, verbose=1)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=128,\n",
    "    epochs=100,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a92f938",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_dict['loss'], label='Treino')\n",
    "plt.plot(history_dict['val_loss'], label='Validação')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_dict['accuracy'], label='Treino')\n",
    "plt.plot(history_dict['val_accuracy'], label='Validação')\n",
    "plt.title('Acurácia')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57845aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs = model_dv.predict(X_val, verbose=0)\n",
    "y_pred_dv = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = y_val  \n",
    "\n",
    "print(classification_report(\n",
    "    y_true, \n",
    "    y_pred, \n",
    "    target_names=label_encoder.classes_  # usa as classes corretas\n",
    "))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print('Confusion matrix:')\n",
    "print(cm)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
    "disp.plot(xticks_rotation=45, cmap='Blues')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f597a622",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_dv, cmap='coolwarm', alpha=0.6)\n",
    "plt.title(\"PCA: drum vs violin\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fff52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_filtered_data(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df[df['class'].isin(['drum', 'violin'])].copy()\n",
    "\n",
    "    df['features'] = df['features'].apply(ast.literal_eval)\n",
    "    X = np.vstack(df['features'].values).astype(np.float32)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(df['class'].values)\n",
    "\n",
    "    return X, y, label_encoder\n",
    "\n",
    "X_dv, y_dv, label_encoder_dv = load_filtered_data(TRAINING_DATASET_TRAIN_METADATA)\n",
    "\n",
    "X_train_dv, X_val_dv, y_train_dv, y_val_dv = train_test_split(\n",
    "    X_dv, y_dv,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_dv\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6f8d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_binary_dense_model(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.BatchNormalization()(inputs)\n",
    "\n",
    "    x = layers.Dense(512, activation='swish', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "\n",
    "    x = layers.Dense(256, activation='swish', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    x = layers.Dense(128, activation='swish', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "\n",
    "    x = layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2965c0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dv = build_binary_dense_model(\n",
    "    input_shape=(160,),\n",
    ")\n",
    "\n",
    "callbacks_dv = [\n",
    "    EarlyStopping(patience=15, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(factor=0.5, patience=10, verbose=1)\n",
    "]\n",
    "\n",
    "history_dv = model_dv.fit(\n",
    "    X_train_dv, y_train_dv,\n",
    "    validation_data=(X_val_dv, y_val_dv),\n",
    "    batch_size=128,\n",
    "    epochs=100,\n",
    "    callbacks=callbacks_dv\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad0a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict_dv = history_dv.history\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_dict_dv['loss'], label='Treino')\n",
    "plt.plot(history_dict_dv['val_loss'], label='Validação')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_dict_dv['accuracy'], label='Treino')\n",
    "plt.plot(history_dict_dv['val_accuracy'], label='Validação')\n",
    "plt.title('Acurácia')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da422339",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs_dv = model_dv.predict(X_val_dv, verbose=0)\n",
    "y_pred_dv = (y_pred_probs_dv > 0.5).astype(int).flatten()\n",
    "y_true_dv = y_val_dv\n",
    "\n",
    "print(classification_report(\n",
    "    y_true_dv, \n",
    "    y_pred_dv, \n",
    "    target_names=label_encoder_dv.classes_\n",
    "))\n",
    "\n",
    "cm_dv = confusion_matrix(y_true_dv, y_pred_dv)\n",
    "print('Confusion matrix (drum vs violin):')\n",
    "print(cm_dv)\n",
    "\n",
    "disp_dv = ConfusionMatrixDisplay(confusion_matrix=cm_dv, display_labels=label_encoder_dv.classes_)\n",
    "disp_dv.plot(xticks_rotation=45, cmap='Blues')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff97512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_dv = PCA(n_components=2)\n",
    "X_pca_dv = pca_dv.fit_transform(X_dv)\n",
    "\n",
    "plt.scatter(X_pca_dv[:, 0], X_pca_dv[:, 1], c=y_dv, cmap='coolwarm', alpha=0.6)\n",
    "plt.title(\"PCA: drum vs violin\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d7a83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_final_batch(X, model, model_dv, label_encoder, label_encoder_dv):\n",
    "    \"\"\"\n",
    "    Predição refinada: usa model principal + model_dv para drum/violin.\n",
    "    Retorna array (N, num_classes) com distribuições softmax finais.\n",
    "    \"\"\"\n",
    "    probs_main = model.predict(X, verbose=0)  # shape (N, num_classes)\n",
    "    preds_main_idx = np.argmax(probs_main, axis=1)\n",
    "    preds_main_name = label_encoder.inverse_transform(preds_main_idx)\n",
    "\n",
    "    # Índices das classes 'drum' e 'violin' no modelo principal\n",
    "    idx_drum = np.where(label_encoder.classes_ == \"drum\")[0][0]\n",
    "    idx_violin = np.where(label_encoder.classes_ == \"violin\")[0][0]\n",
    "\n",
    "    # Identifica quais amostras precisam de refinamento\n",
    "    mask_refine = np.isin(preds_main_name, label_encoder_dv.classes_)\n",
    "    X_refine = X[mask_refine]\n",
    "\n",
    "    if len(X_refine) > 0:\n",
    "        probs_violin = model_dv.predict(X_refine, verbose=0).flatten()  # sigmoid: violin\n",
    "        probs_drum = 1.0 - probs_violin\n",
    "\n",
    "        probs_main_refined = probs_main.copy()\n",
    "\n",
    "        for i, idx in enumerate(np.where(mask_refine)[0]):\n",
    "            probs_main_refined[idx, idx_drum] = probs_drum[i]\n",
    "            probs_main_refined[idx, idx_violin] = probs_violin[i]\n",
    "\n",
    "            # Renormaliza a distribuição (softmax-style)\n",
    "            probs_main_refined[idx] /= probs_main_refined[idx].sum()\n",
    "\n",
    "        return probs_main_refined\n",
    "\n",
    "    return probs_main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999a79a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 Fazer predições usando a função refinada\n",
    "y_pred_probs_final = predict_final_batch(\n",
    "    X_val,\n",
    "    model,\n",
    "    model_dv,\n",
    "    label_encoder,\n",
    "    label_encoder_dv\n",
    ")\n",
    "\n",
    "# 🔹 Inferir a classe com maior probabilidade\n",
    "y_pred_final = np.argmax(y_pred_probs_final, axis=1)\n",
    "y_true_final = y_val\n",
    "\n",
    "# 🔹 Relatório de classificação\n",
    "print(classification_report(\n",
    "    y_true_final, \n",
    "    y_pred_final, \n",
    "    target_names=label_encoder.classes_\n",
    "))\n",
    "\n",
    "# 🔹 Matriz de confusão\n",
    "cm_final = confusion_matrix(y_true_final, y_pred_final)\n",
    "print('Confusion matrix (com refinamento drum/violin):')\n",
    "print(cm_final)\n",
    "\n",
    "disp_final = ConfusionMatrixDisplay(confusion_matrix=cm_final, display_labels=label_encoder.classes_)\n",
    "disp_final.plot(xticks_rotation=45, cmap='Blues')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
