{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc38a96",
   "metadata": {},
   "source": [
    "# DATA PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb87a106",
   "metadata": {},
   "source": [
    "### Download Kaggle dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8a1a65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-insturments/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle downloaded files: /home/rcalabro/.cache/kagglehub/datasets/soumendraprasad/musical-instruments-sound-dataset/versions/3\n",
      "Moved kaggle files to: /home/rcalabro/.cache/kagglehub/datasets/soumendraprasad/musical-instruments-sound-dataset/versions/3\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "dataset_path = '../datasets/raw'\n",
    "force_download = False\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"soumendraprasad/musical-instruments-sound-dataset\", force_download=force_download)\n",
    "print(\"Kaggle downloaded files:\", path)\n",
    "\n",
    "# Cria a pasta de destino, se n√£o existir\n",
    "os.makedirs(dataset_path, exist_ok=True)\n",
    "\n",
    "shutil.copytree(\n",
    "    src=path,\n",
    "    dst=dataset_path,\n",
    "    dirs_exist_ok=True  # Permite copiar para pasta existente\n",
    ")\n",
    "\n",
    "print(\"Moved kaggle files to:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f78511",
   "metadata": {},
   "source": [
    "### Organize files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6331820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "RAW_DATASET_PATH = '../datasets/raw'\n",
    "NORMALIZED_DATASET_PATH = '../datasets/normalized'\n",
    "AUGMENTED_DATASET_PATH = '../datasets/augmented'\n",
    "PREPARED_DATASET_PATH = '../datasets/prepared'\n",
    "\n",
    "os.makedirs(NORMALIZED_DATASET_PATH, exist_ok=True)\n",
    "\n",
    "# Fun√ß√£o para normalizar nomes dos arquivos\n",
    "def normalize_filename(filename: str) -> str:\n",
    "    stem = Path(filename).stem\n",
    "    stem = re.sub(r\"[^a-zA-Z0-9]\", \"_\", stem).lower()\n",
    "    stem = re.sub(r\"_+\", \"_\", stem).strip(\"_\")\n",
    "    return f\"{stem}.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2baf0261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW_TRAIN_CSV_PATH: ../datasets/raw/Metadata_Train.csv\n",
      "RAW_TRAIN_AUDIOS_DIR: ../datasets/raw/Train_submission/Train_submission\n",
      "RAW_TEST_CSV_PATH: ../datasets/raw/Metadata_Test.csv\n",
      "RAW_TEST_AUDIOS_DIR: ../datasets/raw/Test_submission/Test_submission\n"
     ]
    }
   ],
   "source": [
    "# Caminhos RAW\n",
    "RAW_TRAIN_CSV_PATH = Path(os.path.join(RAW_DATASET_PATH, 'Metadata_Train.csv'))\n",
    "print(f\"RAW_TRAIN_CSV_PATH: {RAW_TRAIN_CSV_PATH}\")\n",
    "\n",
    "RAW_TRAIN_AUDIOS_DIR = Path(os.path.join(RAW_DATASET_PATH, 'Train_submission', 'Train_submission'))\n",
    "print(f\"RAW_TRAIN_AUDIOS_DIR: {RAW_TRAIN_AUDIOS_DIR}\")\n",
    "\n",
    "RAW_TEST_CSV_PATH = Path(os.path.join(RAW_DATASET_PATH, 'Metadata_Test.csv'))\n",
    "print(f\"RAW_TEST_CSV_PATH: {RAW_TEST_CSV_PATH}\")\n",
    "\n",
    "RAW_TEST_AUDIOS_DIR = Path(os.path.join(RAW_DATASET_PATH, 'Test_submission', 'Test_submission'))\n",
    "print(f\"RAW_TEST_AUDIOS_DIR: {RAW_TEST_AUDIOS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc23d677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMALIZED_TRAIN_CSV_PATH: ../datasets/normalized/train_metadata.csv\n",
      "NORMALIZED_TRAIN_AUDIOS_DIR: ../datasets/normalized/train_data\n",
      "NORMALIZED_TEST_CSV_PATH: ../datasets/normalized/test_metadata.csv\n",
      "NORMALIZED_TEST_AUDIOS_DIR: ../datasets/normalized/test_data\n"
     ]
    }
   ],
   "source": [
    "# Caminhos NORMALIZED\n",
    "NORMALIZED_TRAIN_CSV_PATH = Path(os.path.join(NORMALIZED_DATASET_PATH, 'train_metadata.csv'))\n",
    "print(f\"NORMALIZED_TRAIN_CSV_PATH: {NORMALIZED_TRAIN_CSV_PATH}\")\n",
    "\n",
    "NORMALIZED_TRAIN_AUDIOS_DIR = Path(os.path.join(NORMALIZED_DATASET_PATH, 'train_data'))\n",
    "print(f\"NORMALIZED_TRAIN_AUDIOS_DIR: {NORMALIZED_TRAIN_AUDIOS_DIR}\")\n",
    "\n",
    "NORMALIZED_TEST_CSV_PATH = Path(os.path.join(NORMALIZED_DATASET_PATH, 'test_metadata.csv'))\n",
    "print(f\"NORMALIZED_TEST_CSV_PATH: {NORMALIZED_TEST_CSV_PATH}\")\n",
    "\n",
    "NORMALIZED_TEST_AUDIOS_DIR = Path(os.path.join(NORMALIZED_DATASET_PATH, 'test_data'))\n",
    "print(f\"NORMALIZED_TEST_AUDIOS_DIR: {NORMALIZED_TEST_AUDIOS_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16df6045",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd5822b",
   "metadata": {},
   "source": [
    "#### Normalize test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee35e087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>Class</th>\n",
       "      <th>OriginalFilename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acoustic_guitar_logo_13084.wav</td>\n",
       "      <td>guitar</td>\n",
       "      <td>acoustic-guitar-logo-13084.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>guitar_chords_70663.wav</td>\n",
       "      <td>guitar</td>\n",
       "      <td>guitar-chords-70663.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>guitar_intro_110935.wav</td>\n",
       "      <td>guitar</td>\n",
       "      <td>guitar-intro-110935.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>guitar_solo_27194.wav</td>\n",
       "      <td>guitar</td>\n",
       "      <td>guitar-solo-27194.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>guitar_solo_5999.wav</td>\n",
       "      <td>guitar</td>\n",
       "      <td>guitar-solo-5999.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         FileName   Class                OriginalFilename\n",
       "0  acoustic_guitar_logo_13084.wav  guitar  acoustic-guitar-logo-13084.wav\n",
       "1         guitar_chords_70663.wav  guitar         guitar-chords-70663.wav\n",
       "2         guitar_intro_110935.wav  guitar         guitar-intro-110935.wav\n",
       "3           guitar_solo_27194.wav  guitar           guitar-solo-27194.wav\n",
       "4            guitar_solo_5999.wav  guitar            guitar-solo-5999.wav"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leitura do CSV\n",
    "df = pd.read_csv(RAW_TEST_CSV_PATH)\n",
    "\n",
    "# Corre√ß√£o e normaliza√ß√£o da coluna de classe\n",
    "df[\"Class\"] = (\n",
    "    df[\"Class\"]\n",
    "    .str.lower()\n",
    "    .str.replace(r\"^sound_\", \"\", regex=True)\n",
    "    .str.replace(r\"(?i)^guiatr$\", \"guitar\", regex=True)\n",
    ")\n",
    "\n",
    "# Guarda o nome original antes da normaliza√ß√£o\n",
    "df[\"OriginalFilename\"] = df[\"FileName\"]\n",
    "\n",
    "# Normaliza o nome dos arquivos\n",
    "df[\"FileName\"] = df[\"FileName\"].apply(normalize_filename)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b72f6c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(NORMALIZED_DATASET_PATH, exist_ok=True)\n",
    "NORMALIZED_TEST_AUDIOS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b8f2dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing: []\n"
     ]
    }
   ],
   "source": [
    "missing_test_files = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    original_file = RAW_TEST_AUDIOS_DIR / row[\"OriginalFilename\"]\n",
    "    normalized_file = NORMALIZED_TEST_AUDIOS_DIR / row[\"FileName\"]\n",
    "\n",
    "    if original_file.exists():\n",
    "        shutil.copy2(original_file, normalized_file)\n",
    "    else:\n",
    "        missing_test_files.append(str(original_file))\n",
    "\n",
    "print(f\"missing: {missing_test_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6607ca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"OriginalFilename\"])\n",
    "df.columns = (\n",
    "    df.columns\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace(r\"[^a-z0-9]+\", \"_\", regex=True)\n",
    "    .str.strip(\"_\")\n",
    ")\n",
    "\n",
    "df.to_csv(NORMALIZED_TEST_CSV_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f750bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Arquivos normalizados e copiados para: ../datasets/normalized/test_data\n",
      "üìÑ Novo CSV salvo em: ../datasets/normalized/test_metadata.csv\n",
      "üéâ Todos os arquivos foram encontrados e copiados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "print(f\"‚úÖ Arquivos normalizados e copiados para: {NORMALIZED_TEST_AUDIOS_DIR}\")\n",
    "print(f\"üìÑ Novo CSV salvo em: {NORMALIZED_TEST_CSV_PATH}\")\n",
    "\n",
    "if missing_test_files:\n",
    "    print(f\"‚ö†Ô∏è Arquivos ausentes ({len(missing_test_files)}):\")\n",
    "    for f in missing_test_files[:5]:\n",
    "        print(f\" - {f}\")\n",
    "else:\n",
    "    print(\"üéâ Todos os arquivos foram encontrados e copiados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8e1189",
   "metadata": {},
   "source": [
    "#### Normalize Train Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad4352f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>Class</th>\n",
       "      <th>OriginalFilename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_e1_major_00.wav</td>\n",
       "      <td>guitar</td>\n",
       "      <td>1-E1-Major 00.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_e1_major_01.wav</td>\n",
       "      <td>guitar</td>\n",
       "      <td>1-E1-Major 01.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_e1_major_02.wav</td>\n",
       "      <td>guitar</td>\n",
       "      <td>1-E1-Major 02.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_e1_major_03.wav</td>\n",
       "      <td>guitar</td>\n",
       "      <td>1-E1-Major 03.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_e1_major_04.wav</td>\n",
       "      <td>guitar</td>\n",
       "      <td>1-E1-Major 04.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            FileName   Class   OriginalFilename\n",
       "0  1_e1_major_00.wav  guitar  1-E1-Major 00.wav\n",
       "1  1_e1_major_01.wav  guitar  1-E1-Major 01.wav\n",
       "2  1_e1_major_02.wav  guitar  1-E1-Major 02.wav\n",
       "3  1_e1_major_03.wav  guitar  1-E1-Major 03.wav\n",
       "4  1_e1_major_04.wav  guitar  1-E1-Major 04.wav"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leitura do CSV\n",
    "df_train = pd.read_csv(RAW_TRAIN_CSV_PATH)\n",
    "\n",
    "# Corre√ß√£o e normaliza√ß√£o da coluna de classe\n",
    "df_train[\"Class\"] = (\n",
    "    df_train[\"Class\"]\n",
    "    .str.lower()\n",
    "    .str.replace(r\"^sound_\", \"\", regex=True)\n",
    "    .str.replace(r\"(?i)^guiatr$\", \"guitar\", regex=True)\n",
    ")\n",
    "\n",
    "# Guarda o nome original antes da normaliza√ß√£o\n",
    "df_train[\"OriginalFilename\"] = df_train[\"FileName\"]\n",
    "\n",
    "# Normaliza o nome dos arquivos\n",
    "df_train[\"FileName\"] = df_train[\"FileName\"].apply(normalize_filename)\n",
    "\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ea598f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(NORMALIZED_DATASET_PATH, exist_ok=True)\n",
    "NORMALIZED_TRAIN_AUDIOS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06a09d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing: []\n"
     ]
    }
   ],
   "source": [
    "missing_train_files = []\n",
    "\n",
    "for _, row in df_train.iterrows():\n",
    "    original_file = RAW_TRAIN_AUDIOS_DIR / row[\"OriginalFilename\"]\n",
    "    normalized_file = NORMALIZED_TRAIN_AUDIOS_DIR / row[\"FileName\"]\n",
    "\n",
    "    if original_file.exists():\n",
    "        shutil.copy2(original_file, normalized_file)\n",
    "    else:\n",
    "        missing_train_files.append(str(original_file))\n",
    "\n",
    "print(f\"missing: {missing_train_files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0459e1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=[\"OriginalFilename\"])\n",
    "df_train.columns = (\n",
    "    df_train.columns\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace(r\"[^a-z0-9]+\", \"_\", regex=True)\n",
    "    .str.strip(\"_\")\n",
    ")\n",
    "\n",
    "df_train.to_csv(NORMALIZED_TRAIN_CSV_PATH, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57e3cbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Arquivos normalizados e copiados para: ../datasets/normalized/train_data\n",
      "üìÑ Novo CSV salvo em: ../datasets/normalized/train_metadata.csv\n",
      "üéâ Todos os arquivos foram encontrados e copiados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "print(f\"‚úÖ Arquivos normalizados e copiados para: {NORMALIZED_TRAIN_AUDIOS_DIR}\")\n",
    "print(f\"üìÑ Novo CSV salvo em: {NORMALIZED_TRAIN_CSV_PATH}\")\n",
    "\n",
    "if missing_train_files:\n",
    "    print(f\"‚ö†Ô∏è Arquivos ausentes ({len(missing_train_files)}):\")\n",
    "    for f in missing_train_files[:5]:\n",
    "        print(f\" - {f}\")\n",
    "else:\n",
    "    print(\"üéâ Todos os arquivos foram encontrados e copiados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12071559",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e1b40caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Vers√£o v1: ../datasets/augmented/v1\n",
      "üìÅ Cortes de treino ser√£o salvos em: ../datasets/augmented/v1/train_data\n",
      "üìÅ Metadados de treino: ../datasets/augmented/v1/train_metadata.csv\n",
      "üìÅ Cortes de treino ser√£o salvos em: ../datasets/augmented/v1/train_data\n",
      "üìÅ Metadados de teste: ../datasets/augmented/v1/train_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "SAMPLE_RATE = 22050\n",
    "MAX_AUGS_PER_ORIGINAL = 4\n",
    "\n",
    "# Vers√£o do dataset preparado\n",
    "AUGMENTATION_VERSION = \"v1\"\n",
    "\n",
    "# Diret√≥rios base\n",
    "AUGMENTED_DATASET_VERSION_PATH = Path(os.path.join(AUGMENTED_DATASET_PATH, AUGMENTATION_VERSION))\n",
    "AUGMENTED_DATASET_VERSION_PATH.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"üìÅ Vers√£o {AUGMENTATION_VERSION}: {AUGMENTED_DATASET_VERSION_PATH}\")\n",
    "\n",
    "AUGMENTED_TRAIN_AUDIOS_DIR = Path(os.path.join(AUGMENTED_DATASET_VERSION_PATH, 'train_data'))\n",
    "AUGMENTED_TRAIN_AUDIOS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "AUGMENTED_TRAIN_CSV_PATH = AUGMENTED_DATASET_VERSION_PATH / \"train_metadata.csv\"\n",
    "print(f\"üìÅ Cortes de treino ser√£o salvos em: {AUGMENTED_TRAIN_AUDIOS_DIR}\")\n",
    "print(f\"üìÅ Metadados de treino: {AUGMENTED_TRAIN_CSV_PATH}\")\n",
    "\n",
    "AUGMENTED_TEST_AUDIOS_DIR = Path(os.path.join(AUGMENTED_DATASET_VERSION_PATH, 'test_data'))\n",
    "AUGMENTED_TEST_AUDIOS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "AUGMENTED_TEST_CSV_PATH = AUGMENTED_DATASET_VERSION_PATH / \"test_metadata.csv\"\n",
    "print(f\"üìÅ Cortes de treino ser√£o salvos em: {AUGMENTED_TRAIN_AUDIOS_DIR}\")\n",
    "print(f\"üìÅ Metadados de teste: {AUGMENTED_TRAIN_CSV_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "947fb533",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENTATION_COMBINATIONS = {\n",
    "    \"original\": [],\n",
    "    \"stretch_102\": [(\"stretch\", 1.02)],\n",
    "    \"pitch_up_0_5\": [(\"pitch\", 0.5)],\n",
    "    \"pitch_down_0_5\": [(\"pitch\", -0.5)],\n",
    "    \"noise_0_003\": [(\"noise\", 0.003)],\n",
    "    \"gain_0_95\": [(\"gain\", 0.95)],\n",
    "    \"gain_1_05\": [(\"gain\", 1.05)],\n",
    "\n",
    "    \"stretch_pitch_up\": [(\"stretch\", 1.02), (\"pitch\", 0.5)],\n",
    "    \"pitch_noise\": [(\"pitch\", -0.5), (\"noise\", 0.002)],\n",
    "    \"stretch_noise\": [(\"stretch\", 0.98), (\"noise\", 0.002)],\n",
    "    \"pitch_gain\": [(\"pitch\", 0.5), (\"gain\", 1.05)],\n",
    "    \"stretch_gain\": [(\"stretch\", 1.02), (\"gain\", 1.05)],\n",
    "}\n",
    "\n",
    "def augment_audio(y, sr, steps):\n",
    "    y_aug = np.copy(y)\n",
    "    for aug_type, param in steps:\n",
    "        if aug_type == \"stretch\":\n",
    "            y_aug = librosa.effects.time_stretch(y_aug, rate=param)\n",
    "        elif aug_type == \"pitch\":\n",
    "            y_aug = librosa.effects.pitch_shift(y_aug, sr=sr, n_steps=param)\n",
    "        elif aug_type == \"noise\":\n",
    "            noise = np.random.normal(0, param, len(y_aug))\n",
    "            y_aug += noise\n",
    "        elif aug_type == \"gain\":\n",
    "            y_aug *= param\n",
    "    return y_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e20d36",
   "metadata": {},
   "source": [
    "#### Augment test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d2aa588",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Augmentation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:47<00:00, 11.76s/it]\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(NORMALIZED_TEST_CSV_PATH)\n",
    "df_test.columns = df_test.columns.str.strip().str.lower().str.replace(r\"[^a-z0-9]+\", \"_\", regex=True)\n",
    "\n",
    "augmented_test_records = []\n",
    "grouped_test = df_test.groupby(\"class\")\n",
    "\n",
    "for class_name, group in tqdm(df_test.groupby(\"class\"), desc=\"Test Augmentation\"):\n",
    "    combo_names = list(AUGMENTATION_COMBINATIONS.keys())\n",
    "    combo_names.remove(\"original\")\n",
    "\n",
    "    for i, row in group.reset_index(drop=True).iterrows():\n",
    "        original_path = NORMALIZED_TEST_AUDIOS_DIR / row[\"filename\"]\n",
    "        if not original_path.exists():\n",
    "            continue\n",
    "\n",
    "        y, sr = librosa.load(original_path, sr=SAMPLE_RATE)\n",
    "\n",
    "        original_filename = f\"{original_path.stem}__original.wav\"\n",
    "        output_original_path = AUGMENTED_TEST_AUDIOS_DIR / original_filename\n",
    "        sf.write(output_original_path, y, sr, format=\"WAV\")\n",
    "        augmented_test_records.append({\n",
    "            \"file_name\": original_filename,\n",
    "            \"class\": class_name,\n",
    "            \"augmentation\": \"original\"\n",
    "        })\n",
    "\n",
    "        shuffled_combos = random.sample(combo_names, k=len(combo_names))\n",
    "        for j in range(MAX_AUGS_PER_ORIGINAL):\n",
    "            combo = shuffled_combos[j % len(shuffled_combos)]\n",
    "            steps = AUGMENTATION_COMBINATIONS[combo]\n",
    "\n",
    "            y_aug = augment_audio(y, sr, steps)\n",
    "            filename_aug = f\"{original_path.stem}__{combo}.wav\"\n",
    "            output_path = AUGMENTED_TEST_AUDIOS_DIR / filename_aug\n",
    "\n",
    "            sf.write(output_path, y_aug, sr, format=\"WAV\")\n",
    "            augmented_test_records.append({\n",
    "                \"file_name\": filename_aug,\n",
    "                \"class\": class_name,\n",
    "                \"augmentation\": combo\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0adcdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ CSV de metadados de teste salvo em: ../datasets/augmented/v1/test_metadata.csv\n",
      "üéß Total de arquivos augmentados no teste: 400\n"
     ]
    }
   ],
   "source": [
    "df_augmented_test = pd.DataFrame(augmented_test_records)\n",
    "df_augmented_test.to_csv(AUGMENTED_TEST_CSV_PATH, index=False)\n",
    "\n",
    "print(f\"üìÑ CSV de metadados de teste salvo em: {AUGMENTED_TEST_CSV_PATH}\")\n",
    "print(f\"üéß Total de arquivos augmentados no teste: {len(df_augmented_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8668724",
   "metadata": {},
   "source": [
    "#### Augment train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "65306a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Augmentation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [20:32<00:00, 308.17s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_train = pd.read_csv(NORMALIZED_TRAIN_CSV_PATH)\n",
    "grouped = df_train.groupby(\"class\")\n",
    "\n",
    "augmented_train_records = []\n",
    "\n",
    "\n",
    "for class_name, group in tqdm(df_train.groupby(\"class\"), desc=\"Train Augmentation\"):\n",
    "    combo_names = list(AUGMENTATION_COMBINATIONS.keys())\n",
    "    combo_names.remove(\"original\")\n",
    "\n",
    "    for i, row in group.reset_index(drop=True).iterrows():\n",
    "        original_path = NORMALIZED_TRAIN_AUDIOS_DIR / row[\"filename\"]\n",
    "        if not original_path.exists():\n",
    "            continue\n",
    "\n",
    "        y, sr = librosa.load(original_path, sr=SAMPLE_RATE)\n",
    "\n",
    "        original_filename = f\"{original_path.stem}__original.wav\"\n",
    "        output_original_path = AUGMENTED_TRAIN_AUDIOS_DIR / original_filename\n",
    "        sf.write(output_original_path, y, sr, format=\"WAV\")\n",
    "        augmented_train_records.append({\n",
    "            \"file_name\": original_filename,\n",
    "            \"class\": class_name,\n",
    "            \"augmentation\": \"original\"\n",
    "        })\n",
    "\n",
    "        shuffled_combos = random.sample(combo_names, k=len(combo_names))\n",
    "        for j in range(MAX_AUGS_PER_ORIGINAL):\n",
    "            combo = shuffled_combos[j % len(shuffled_combos)]\n",
    "            steps = AUGMENTATION_COMBINATIONS[combo]\n",
    "\n",
    "            y_aug = augment_audio(y, sr, steps)\n",
    "            filename_aug = f\"{original_path.stem}__{combo}.wav\"\n",
    "            output_path = AUGMENTED_TRAIN_AUDIOS_DIR / filename_aug\n",
    "\n",
    "            sf.write(output_path, y_aug, sr, format=\"WAV\")\n",
    "            augmented_train_records.append({\n",
    "                \"file_name\": filename_aug,\n",
    "                \"class\": class_name,\n",
    "                \"augmentation\": combo\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f1883cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ CSV de metadados salvo em: ../datasets/augmented/v1/train_metadata.csv\n",
      "üéß Total de arquivos augmentados: 13145\n"
     ]
    }
   ],
   "source": [
    "df_augmented_train = pd.DataFrame(augmented_train_records)\n",
    "df_augmented_train.to_csv(AUGMENTED_TRAIN_CSV_PATH, index=False)\n",
    "\n",
    "print(f\"üìÑ CSV de metadados salvo em: {AUGMENTED_TRAIN_CSV_PATH}\")\n",
    "print(f\"üéß Total de arquivos augmentados: {len(df_augmented_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255cc6d7",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eb973c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Vers√£o v1: ../datasets/prepared/v1\n",
      "üìÅ Cortes de treino ser√£o salvos em: ../datasets/prepared/v1/train_data\n",
      "üìÅ Cortes de teste ser√£o salvos em: ../datasets/prepared/v1/train_data\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "WINDOW_SIZE = 3.0    # segundos\n",
    "OVERLAP = 1.5        # segundos\n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "PREPARATION_VERSION = \"v1\"\n",
    "AUGMENTATION_VERSION_SOURCE = \"v1\"\n",
    "\n",
    "# Diret√≥rios base\n",
    "PREPARED_DATASET_VERSION_PATH = Path(os.path.join(PREPARED_DATASET_PATH, PREPARATION_VERSION))\n",
    "PREPARED_DATASET_VERSION_PATH.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"üìÅ Vers√£o {PREPARATION_VERSION}: {PREPARED_DATASET_VERSION_PATH}\")\n",
    "\n",
    "PREPARED_TRAIN_AUDIOS_DIR = Path(os.path.join(PREPARED_DATASET_VERSION_PATH, 'train_data'))\n",
    "PREPARED_TRAIN_AUDIOS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"üìÅ Cortes de treino ser√£o salvos em: {PREPARED_TRAIN_AUDIOS_DIR}\")\n",
    "\n",
    "PREPARED_TEST_AUDIOS_DIR = Path(os.path.join(PREPARED_DATASET_VERSION_PATH, 'test_data'))\n",
    "PREPARED_TEST_AUDIOS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"üìÅ Cortes de teste ser√£o salvos em: {PREPARED_TRAIN_AUDIOS_DIR}\")\n",
    "\n",
    "AUGMENTED_PREPARE_DATASET_VERSION_PATH = Path(os.path.join(AUGMENTED_DATASET_PATH, AUGMENTATION_VERSION_SOURCE))\n",
    "\n",
    "\n",
    "AUGMENTED_PREPARE_TEST_AUDIOS_DIR = Path(os.path.join(AUGMENTED_DATASET_VERSION_PATH, 'test_data'))\n",
    "AUGMENTED_PREPARE_TEST_CSV_PATH = AUGMENTED_PREPARE_DATASET_VERSION_PATH / \"test_metadata.csv\"\n",
    "\n",
    "AUGMENTED_PREPARE_TRAIN_AUDIOS_DIR = Path(os.path.join(AUGMENTED_DATASET_VERSION_PATH, 'train_data'))\n",
    "AUGMENTED_PREPARE_TRAIN_CSV_PATH = AUGMENTED_PREPARE_DATASET_VERSION_PATH / \"train_metadata.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "614c51fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_audio_with_overlap(file_path: Path, class_name: str, output_dir: Path, \n",
    "                             window_size: float, overlap: float, sample_rate: int = 22050):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=sample_rate)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao carregar {file_path.name}: {e}\")\n",
    "        return []\n",
    "\n",
    "    window_samples = int(window_size * sr)\n",
    "    hop_samples = int((window_size - overlap) * sr)\n",
    "\n",
    "    segments = []\n",
    "    base_name = file_path.stem  # Nome base sem extens√£o\n",
    "\n",
    "    for i, start in enumerate(range(0, len(y), hop_samples)):\n",
    "        end = start + window_samples\n",
    "        slice_audio = y[start:end]\n",
    "\n",
    "        # Padding com zeros se for menor que o necess√°rio\n",
    "        if len(slice_audio) < window_samples:\n",
    "            slice_audio = np.pad(slice_audio, (0, window_samples - len(slice_audio)))\n",
    "\n",
    "        # Gera nome padronizado com extens√£o .wav\n",
    "        filename_seq = f\"{base_name}_{i+1:06}.wav\"\n",
    "        out_path = output_dir / filename_seq\n",
    "\n",
    "        try:\n",
    "            sf.write(out_path, slice_audio, sr, format='WAV')\n",
    "            segments.append((filename_seq, class_name))\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro ao salvar {out_path.name}: {e}\")\n",
    "\n",
    "        if end >= len(y):\n",
    "            break\n",
    "\n",
    "    return segments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c6e19d",
   "metadata": {},
   "source": [
    "#### Prepare test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a78d7af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:06<00:00, 12.18it/s]\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(NORMALIZED_TEST_CSV_PATH)\n",
    "\n",
    "prepared_test_data = []\n",
    "\n",
    "for _, row in tqdm(df_test.iterrows(), total=len(df_test)):\n",
    "    original_path = NORMALIZED_TEST_AUDIOS_DIR / row[\"filename\"]\n",
    "    class_name = row[\"class\"]\n",
    "\n",
    "    if original_path.exists():\n",
    "        segments = slice_audio_with_overlap(\n",
    "            file_path=original_path,\n",
    "            class_name=class_name,\n",
    "            output_dir=PREPARED_TEST_AUDIOS_DIR,\n",
    "            window_size=WINDOW_SIZE,\n",
    "            overlap=OVERLAP,\n",
    "            sample_rate=SAMPLE_RATE\n",
    "        )\n",
    "        prepared_test_data.extend(segments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "008508c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Metadata de teste salva em: ../datasets/prepared/v1/test_metadata.csv\n",
      "üéß Total de segmentos: 1238\n"
     ]
    }
   ],
   "source": [
    "df_prepared_test = pd.DataFrame(prepared_test_data, columns=[\"filename\", \"class\"])\n",
    "\n",
    "PREPARED_TEST_CSV_PATH = PREPARED_DATASET_VERSION_PATH / \"test_metadata.csv\"\n",
    "df_prepared_test.to_csv(PREPARED_TEST_CSV_PATH, index=False)\n",
    "\n",
    "print(f\"üìÑ Metadata de teste salva em: {PREPARED_TEST_CSV_PATH}\")\n",
    "print(f\"üéß Total de segmentos: {len(df_prepared_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc2b1eb",
   "metadata": {},
   "source": [
    "#### Prepare train files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "640a61b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2629/2629 [02:51<00:00, 15.30it/s]\n"
     ]
    }
   ],
   "source": [
    "prepared_train_data = []\n",
    "\n",
    "for _, row in tqdm(df_train.iterrows(), total=len(df_train)):\n",
    "    original_path = NORMALIZED_TRAIN_AUDIOS_DIR / row[\"filename\"]\n",
    "    class_name = row[\"class\"]\n",
    "\n",
    "    if original_path.exists():\n",
    "        segments = slice_audio_with_overlap(\n",
    "            file_path=original_path,\n",
    "            class_name=class_name,\n",
    "            output_dir=PREPARED_TRAIN_AUDIOS_DIR,\n",
    "            window_size=WINDOW_SIZE,\n",
    "            overlap=OVERLAP,\n",
    "            sample_rate=SAMPLE_RATE\n",
    "        )\n",
    "        prepared_train_data.extend(segments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fadd8042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Metadata de treino salva em: ../datasets/prepared/v1/train_prepared_metadata.csv\n",
      "üéß Total de segmentos: 29893\n"
     ]
    }
   ],
   "source": [
    "df_prepared_train = pd.DataFrame(prepared_train_data, columns=[\"file_name\", \"class\"])\n",
    "\n",
    "PREPARED_TRAIN_CSV_PATH = PREPARED_DATASET_VERSION_PATH / \"train_prepared_metadata.csv\"\n",
    "df_prepared_train.to_csv(PREPARED_TRAIN_CSV_PATH, index=False)\n",
    "\n",
    "print(f\"üìÑ Metadata de treino salva em: {PREPARED_TRAIN_CSV_PATH}\")\n",
    "print(f\"üéß Total de segmentos: {len(df_prepared_train)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
