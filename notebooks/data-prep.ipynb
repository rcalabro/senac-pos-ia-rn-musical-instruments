{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc38a96",
   "metadata": {},
   "source": [
    "# DATA PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb87a106",
   "metadata": {},
   "source": [
    "### Download Kaggle dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8a1a65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rcalabro/codebase/senac-ia/neural-networks/rn-musical-insturments/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle downloaded files: /home/rcalabro/.cache/kagglehub/datasets/soumendraprasad/musical-instruments-sound-dataset/versions/3\n",
      "Moved kaggle files to: /home/rcalabro/.cache/kagglehub/datasets/soumendraprasad/musical-instruments-sound-dataset/versions/3\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "dataset_path = '../datasets/raw'\n",
    "force_download = False\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"soumendraprasad/musical-instruments-sound-dataset\", force_download=force_download)\n",
    "print(\"Kaggle downloaded files:\", path)\n",
    "\n",
    "# Cria a pasta de destino, se n√£o existir\n",
    "os.makedirs(dataset_path, exist_ok=True)\n",
    "\n",
    "shutil.copytree(\n",
    "    src=path,\n",
    "    dst=dataset_path,\n",
    "    dirs_exist_ok=True  # Permite copiar para pasta existente\n",
    ")\n",
    "\n",
    "print(\"Moved kaggle files to:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f78511",
   "metadata": {},
   "source": [
    "### Organize files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6331820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "RAW_DATASET_PATH = '../datasets/raw'\n",
    "NORMALIZED_DATASET_PATH = '../datasets/normalized'\n",
    "AUGMENTED_DATASET_PATH = '../datasets/augmented'\n",
    "PREPARED_DATASET_PATH = '../datasets/prepared'\n",
    "\n",
    "os.makedirs(NORMALIZED_DATASET_PATH, exist_ok=True)\n",
    "\n",
    "# Fun√ß√£o para normalizar nomes dos arquivos\n",
    "def normalize_filename(filename: str) -> str:\n",
    "    stem = Path(filename).stem\n",
    "    stem = re.sub(r\"[^a-zA-Z0-9]\", \"_\", stem).lower()\n",
    "    stem = re.sub(r\"_+\", \"_\", stem).strip(\"_\")\n",
    "    return f\"{stem}.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2baf0261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW_TRAIN_CSV_PATH: ../datasets/raw/Metadata_Train.csv\n",
      "RAW_TRAIN_AUDIOS_DIR: ../datasets/raw/Train_submission/Train_submission\n",
      "RAW_TEST_CSV_PATH: ../datasets/raw/Metadata_Test.csv\n",
      "RAW_TEST_AUDIOS_DIR: ../datasets/raw/Test_submission/Test_submission\n"
     ]
    }
   ],
   "source": [
    "# Caminhos RAW\n",
    "RAW_TRAIN_CSV_PATH = Path(os.path.join(RAW_DATASET_PATH, 'Metadata_Train.csv'))\n",
    "print(f\"RAW_TRAIN_CSV_PATH: {RAW_TRAIN_CSV_PATH}\")\n",
    "\n",
    "RAW_TRAIN_AUDIOS_DIR = Path(os.path.join(RAW_DATASET_PATH, 'Train_submission', 'Train_submission'))\n",
    "print(f\"RAW_TRAIN_AUDIOS_DIR: {RAW_TRAIN_AUDIOS_DIR}\")\n",
    "\n",
    "RAW_TEST_CSV_PATH = Path(os.path.join(RAW_DATASET_PATH, 'Metadata_Test.csv'))\n",
    "print(f\"RAW_TEST_CSV_PATH: {RAW_TEST_CSV_PATH}\")\n",
    "\n",
    "RAW_TEST_AUDIOS_DIR = Path(os.path.join(RAW_DATASET_PATH, 'Test_submission', 'Test_submission'))\n",
    "print(f\"RAW_TEST_AUDIOS_DIR: {RAW_TEST_AUDIOS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc23d677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMALIZED_TRAIN_CSV_PATH: ../datasets/normalized/train_metadata.csv\n",
      "NORMALIZED_TRAIN_AUDIOS_DIR: ../datasets/normalized/train_data\n",
      "NORMALIZED_TEST_CSV_PATH: ../datasets/normalized/test_metadata.csv\n",
      "NORMALIZED_TEST_AUDIOS_DIR: ../datasets/normalized/test_data\n"
     ]
    }
   ],
   "source": [
    "# Caminhos NORMALIZED\n",
    "NORMALIZED_TRAIN_CSV_PATH = Path(os.path.join(NORMALIZED_DATASET_PATH, 'train_metadata.csv'))\n",
    "print(f\"NORMALIZED_TRAIN_CSV_PATH: {NORMALIZED_TRAIN_CSV_PATH}\")\n",
    "\n",
    "NORMALIZED_TRAIN_AUDIOS_DIR = Path(os.path.join(NORMALIZED_DATASET_PATH, 'train_data'))\n",
    "print(f\"NORMALIZED_TRAIN_AUDIOS_DIR: {NORMALIZED_TRAIN_AUDIOS_DIR}\")\n",
    "\n",
    "NORMALIZED_TEST_CSV_PATH = Path(os.path.join(NORMALIZED_DATASET_PATH, 'test_metadata.csv'))\n",
    "print(f\"NORMALIZED_TEST_CSV_PATH: {NORMALIZED_TEST_CSV_PATH}\")\n",
    "\n",
    "NORMALIZED_TEST_AUDIOS_DIR = Path(os.path.join(NORMALIZED_DATASET_PATH, 'test_data'))\n",
    "print(f\"NORMALIZED_TEST_AUDIOS_DIR: {NORMALIZED_TEST_AUDIOS_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16df6045",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd5822b",
   "metadata": {},
   "source": [
    "#### Normalize test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee35e087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>Class</th>\n",
       "      <th>OriginalFilename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acoustic_guitar_logo_13084.wav</td>\n",
       "      <td>guitar</td>\n",
       "      <td>acoustic-guitar-logo-13084.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>guitar_chords_70663.wav</td>\n",
       "      <td>guitar</td>\n",
       "      <td>guitar-chords-70663.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>guitar_intro_110935.wav</td>\n",
       "      <td>guitar</td>\n",
       "      <td>guitar-intro-110935.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>guitar_solo_27194.wav</td>\n",
       "      <td>guitar</td>\n",
       "      <td>guitar-solo-27194.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>guitar_solo_5999.wav</td>\n",
       "      <td>guitar</td>\n",
       "      <td>guitar-solo-5999.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         FileName   Class                OriginalFilename\n",
       "0  acoustic_guitar_logo_13084.wav  guitar  acoustic-guitar-logo-13084.wav\n",
       "1         guitar_chords_70663.wav  guitar         guitar-chords-70663.wav\n",
       "2         guitar_intro_110935.wav  guitar         guitar-intro-110935.wav\n",
       "3           guitar_solo_27194.wav  guitar           guitar-solo-27194.wav\n",
       "4            guitar_solo_5999.wav  guitar            guitar-solo-5999.wav"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leitura do CSV\n",
    "df = pd.read_csv(RAW_TEST_CSV_PATH)\n",
    "\n",
    "# Corre√ß√£o e normaliza√ß√£o da coluna de classe\n",
    "df[\"Class\"] = (\n",
    "    df[\"Class\"]\n",
    "    .str.lower()\n",
    "    .str.replace(r\"^sound_\", \"\", regex=True)\n",
    "    .str.replace(r\"(?i)^guiatr$\", \"guitar\", regex=True)\n",
    ")\n",
    "\n",
    "# Guarda o nome original antes da normaliza√ß√£o\n",
    "df[\"OriginalFilename\"] = df[\"FileName\"]\n",
    "\n",
    "# Normaliza o nome dos arquivos\n",
    "df[\"FileName\"] = df[\"FileName\"].apply(normalize_filename)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b72f6c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(NORMALIZED_DATASET_PATH, exist_ok=True)\n",
    "NORMALIZED_TEST_AUDIOS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b8f2dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing: []\n"
     ]
    }
   ],
   "source": [
    "missing_test_files = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    original_file = RAW_TEST_AUDIOS_DIR / row[\"OriginalFilename\"]\n",
    "    normalized_file = NORMALIZED_TEST_AUDIOS_DIR / row[\"FileName\"]\n",
    "\n",
    "    if original_file.exists():\n",
    "        shutil.copy2(original_file, normalized_file)\n",
    "    else:\n",
    "        missing_test_files.append(str(original_file))\n",
    "\n",
    "print(f\"missing: {missing_test_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6607ca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"OriginalFilename\"])\n",
    "df.columns = (\n",
    "    df.columns\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace(r\"[^a-z0-9]+\", \"_\", regex=True)\n",
    "    .str.strip(\"_\")\n",
    ")\n",
    "\n",
    "df.to_csv(NORMALIZED_TEST_CSV_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f750bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Arquivos normalizados e copiados para: ../datasets/normalized/test_data\n",
      "üìÑ Novo CSV salvo em: ../datasets/normalized/test_metadata.csv\n",
      "üéâ Todos os arquivos foram encontrados e copiados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "print(f\"‚úÖ Arquivos normalizados e copiados para: {NORMALIZED_TEST_AUDIOS_DIR}\")\n",
    "print(f\"üìÑ Novo CSV salvo em: {NORMALIZED_TEST_CSV_PATH}\")\n",
    "\n",
    "if missing_test_files:\n",
    "    print(f\"‚ö†Ô∏è Arquivos ausentes ({len(missing_test_files)}):\")\n",
    "    for f in missing_test_files[:5]:\n",
    "        print(f\" - {f}\")\n",
    "else:\n",
    "    print(\"üéâ Todos os arquivos foram encontrados e copiados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8e1189",
   "metadata": {},
   "source": [
    "#### Normalize Train Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad4352f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>Class</th>\n",
       "      <th>OriginalFilename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_e1_major_00.wav</td>\n",
       "      <td>guitar</td>\n",
       "      <td>1-E1-Major 00.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_e1_major_01.wav</td>\n",
       "      <td>guitar</td>\n",
       "      <td>1-E1-Major 01.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_e1_major_02.wav</td>\n",
       "      <td>guitar</td>\n",
       "      <td>1-E1-Major 02.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_e1_major_03.wav</td>\n",
       "      <td>guitar</td>\n",
       "      <td>1-E1-Major 03.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_e1_major_04.wav</td>\n",
       "      <td>guitar</td>\n",
       "      <td>1-E1-Major 04.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            FileName   Class   OriginalFilename\n",
       "0  1_e1_major_00.wav  guitar  1-E1-Major 00.wav\n",
       "1  1_e1_major_01.wav  guitar  1-E1-Major 01.wav\n",
       "2  1_e1_major_02.wav  guitar  1-E1-Major 02.wav\n",
       "3  1_e1_major_03.wav  guitar  1-E1-Major 03.wav\n",
       "4  1_e1_major_04.wav  guitar  1-E1-Major 04.wav"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leitura do CSV\n",
    "df_train = pd.read_csv(RAW_TRAIN_CSV_PATH)\n",
    "\n",
    "# Corre√ß√£o e normaliza√ß√£o da coluna de classe\n",
    "df_train[\"Class\"] = (\n",
    "    df_train[\"Class\"]\n",
    "    .str.lower()\n",
    "    .str.replace(r\"^sound_\", \"\", regex=True)\n",
    "    .str.replace(r\"(?i)^guiatr$\", \"guitar\", regex=True)\n",
    ")\n",
    "\n",
    "# Guarda o nome original antes da normaliza√ß√£o\n",
    "df_train[\"OriginalFilename\"] = df_train[\"FileName\"]\n",
    "\n",
    "# Normaliza o nome dos arquivos\n",
    "df_train[\"FileName\"] = df_train[\"FileName\"].apply(normalize_filename)\n",
    "\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ea598f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(NORMALIZED_DATASET_PATH, exist_ok=True)\n",
    "NORMALIZED_TRAIN_AUDIOS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06a09d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing: []\n"
     ]
    }
   ],
   "source": [
    "missing_train_files = []\n",
    "\n",
    "for _, row in df_train.iterrows():\n",
    "    original_file = RAW_TRAIN_AUDIOS_DIR / row[\"OriginalFilename\"]\n",
    "    normalized_file = NORMALIZED_TRAIN_AUDIOS_DIR / row[\"FileName\"]\n",
    "\n",
    "    if original_file.exists():\n",
    "        shutil.copy2(original_file, normalized_file)\n",
    "    else:\n",
    "        missing_train_files.append(str(original_file))\n",
    "\n",
    "print(f\"missing: {missing_train_files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0459e1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=[\"OriginalFilename\"])\n",
    "df_train.columns = (\n",
    "    df_train.columns\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace(r\"[^a-z0-9]+\", \"_\", regex=True)\n",
    "    .str.strip(\"_\")\n",
    ")\n",
    "\n",
    "df_train.to_csv(NORMALIZED_TRAIN_CSV_PATH, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57e3cbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Arquivos normalizados e copiados para: ../datasets/normalized/train_data\n",
      "üìÑ Novo CSV salvo em: ../datasets/normalized/train_metadata.csv\n",
      "üéâ Todos os arquivos foram encontrados e copiados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "print(f\"‚úÖ Arquivos normalizados e copiados para: {NORMALIZED_TRAIN_AUDIOS_DIR}\")\n",
    "print(f\"üìÑ Novo CSV salvo em: {NORMALIZED_TRAIN_CSV_PATH}\")\n",
    "\n",
    "if missing_train_files:\n",
    "    print(f\"‚ö†Ô∏è Arquivos ausentes ({len(missing_train_files)}):\")\n",
    "    for f in missing_train_files[:5]:\n",
    "        print(f\" - {f}\")\n",
    "else:\n",
    "    print(\"üéâ Todos os arquivos foram encontrados e copiados com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12071559",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1b40caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Vers√£o v1: ../datasets/augmented/v1\n",
      "üìÅ Cortes de treino ser√£o salvos em: ../datasets/augmented/v1/train_data\n",
      "üìÅ Metadados de treino: ../datasets/augmented/v1/train_metadata.csv\n",
      "üìÅ Cortes de treino ser√£o salvos em: ../datasets/augmented/v1/train_data\n",
      "üìÅ Metadados de teste: ../datasets/augmented/v1/train_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "SAMPLE_RATE = 22050\n",
    "MAX_AUGS_PER_ORIGINAL = 4\n",
    "\n",
    "# Vers√£o do dataset preparado\n",
    "AUGMENTATION_VERSION = \"v1\"\n",
    "\n",
    "# Diret√≥rios base\n",
    "AUGMENTED_DATASET_VERSION_PATH = Path(os.path.join(AUGMENTED_DATASET_PATH, AUGMENTATION_VERSION))\n",
    "AUGMENTED_DATASET_VERSION_PATH.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"üìÅ Vers√£o {AUGMENTATION_VERSION}: {AUGMENTED_DATASET_VERSION_PATH}\")\n",
    "\n",
    "AUGMENTED_TRAIN_AUDIOS_DIR = Path(os.path.join(AUGMENTED_DATASET_VERSION_PATH, 'train_data'))\n",
    "AUGMENTED_TRAIN_AUDIOS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "AUGMENTED_TRAIN_CSV_PATH = AUGMENTED_DATASET_VERSION_PATH / \"train_metadata.csv\"\n",
    "print(f\"üìÅ Cortes de treino ser√£o salvos em: {AUGMENTED_TRAIN_AUDIOS_DIR}\")\n",
    "print(f\"üìÅ Metadados de treino: {AUGMENTED_TRAIN_CSV_PATH}\")\n",
    "\n",
    "AUGMENTED_TEST_AUDIOS_DIR = Path(os.path.join(AUGMENTED_DATASET_VERSION_PATH, 'test_data'))\n",
    "AUGMENTED_TEST_AUDIOS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "AUGMENTED_TEST_CSV_PATH = AUGMENTED_DATASET_VERSION_PATH / \"test_metadata.csv\"\n",
    "print(f\"üìÅ Cortes de treino ser√£o salvos em: {AUGMENTED_TRAIN_AUDIOS_DIR}\")\n",
    "print(f\"üìÅ Metadados de teste: {AUGMENTED_TRAIN_CSV_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "947fb533",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENTATION_COMBINATIONS = {\n",
    "    \"original\": [],\n",
    "    \"stretch_102\": [(\"stretch\", 1.02)],\n",
    "    \"pitch_up_0_5\": [(\"pitch\", 0.5)],\n",
    "    \"pitch_down_0_5\": [(\"pitch\", -0.5)],\n",
    "    \"noise_0_003\": [(\"noise\", 0.003)],\n",
    "    \"gain_0_95\": [(\"gain\", 0.95)],\n",
    "    \"gain_1_05\": [(\"gain\", 1.05)],\n",
    "\n",
    "    \"stretch_pitch_up\": [(\"stretch\", 1.02), (\"pitch\", 0.5)],\n",
    "    \"pitch_noise\": [(\"pitch\", -0.5), (\"noise\", 0.002)],\n",
    "    \"stretch_noise\": [(\"stretch\", 0.98), (\"noise\", 0.002)],\n",
    "    \"pitch_gain\": [(\"pitch\", 0.5), (\"gain\", 1.05)],\n",
    "    \"stretch_gain\": [(\"stretch\", 1.02), (\"gain\", 1.05)],\n",
    "}\n",
    "\n",
    "def augment_audio(y, sr, steps):\n",
    "    y_aug = np.copy(y)\n",
    "    for aug_type, param in steps:\n",
    "        if aug_type == \"stretch\":\n",
    "            y_aug = librosa.effects.time_stretch(y_aug, rate=param)\n",
    "        elif aug_type == \"pitch\":\n",
    "            y_aug = librosa.effects.pitch_shift(y_aug, sr=sr, n_steps=param)\n",
    "        elif aug_type == \"noise\":\n",
    "            noise = np.random.normal(0, param, len(y_aug))\n",
    "            y_aug += noise\n",
    "        elif aug_type == \"gain\":\n",
    "            y_aug *= param\n",
    "    return y_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e20d36",
   "metadata": {},
   "source": [
    "#### Augment test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2aa588",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmentation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:43<00:00, 10.86s/it]\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(NORMALIZED_TEST_CSV_PATH)\n",
    "df_test.columns = df_test.columns.str.strip().str.lower().str.replace(r\"[^a-z0-9]+\", \"_\", regex=True)\n",
    "\n",
    "augmented_test_records = []\n",
    "grouped_test = df_test.groupby(\"class\")\n",
    "\n",
    "for class_name, group in tqdm(df_test.groupby(\"class\"), desc=\"Augmentation\"):\n",
    "    combo_names = list(AUGMENTATION_COMBINATIONS.keys())\n",
    "    combo_names.remove(\"original\")\n",
    "\n",
    "    for i, row in group.reset_index(drop=True).iterrows():\n",
    "        original_path = NORMALIZED_TEST_AUDIOS_DIR / row[\"filename\"]\n",
    "        if not original_path.exists():\n",
    "            continue\n",
    "\n",
    "        y, sr = librosa.load(original_path, sr=SAMPLE_RATE)\n",
    "\n",
    "        original_filename = f\"{original_path.stem}__original.wav\"\n",
    "        output_original_path = AUGMENTED_TEST_AUDIOS_DIR / original_filename\n",
    "        sf.write(output_original_path, y, sr, format=\"WAV\")\n",
    "        augmented_test_records.append({\n",
    "            \"file_name\": original_filename,\n",
    "            \"class\": class_name,\n",
    "            \"augmentation\": \"original\"\n",
    "        })\n",
    "\n",
    "        for j in range(MAX_AUGS_PER_ORIGINAL):\n",
    "            combo = combo_names[j % len(combo_names)]\n",
    "            steps = AUGMENTATION_COMBINATIONS[combo]\n",
    "\n",
    "            y_aug = augment_audio(y, sr, steps)\n",
    "            filename_aug = f\"{original_path.stem}__{combo}.wav\"\n",
    "            output_path = AUGMENTED_TEST_AUDIOS_DIR / filename_aug\n",
    "\n",
    "            sf.write(output_path, y_aug, sr, format=\"WAV\")\n",
    "            augmented_test_records.append({\n",
    "                \"file_name\": filename_aug,\n",
    "                \"class\": class_name,\n",
    "                \"augmentation\": combo\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0adcdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ CSV de metadados de teste salvo em: ../datasets/augmented/v1/test_metadata.csv\n",
      "üéß Total de arquivos augmentados no teste: 400\n"
     ]
    }
   ],
   "source": [
    "df_augmented_test = pd.DataFrame(augmented_test_records)\n",
    "df_augmented_test.to_csv(AUGMENTED_TEST_CSV_PATH, index=False)\n",
    "\n",
    "print(f\"üìÑ CSV de metadados de teste salvo em: {AUGMENTED_TEST_CSV_PATH}\")\n",
    "print(f\"üéß Total de arquivos augmentados no teste: {len(df_augmented_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8668724",
   "metadata": {},
   "source": [
    "#### Augment train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65306a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "drum: 700it [04:17,  2.72it/s][00:00<?, ?it/s]\n",
      "guitar: 700it [04:17,  2.72it/s]4:17<12:51, 257.14s/it]\n",
      "piano: 250it [03:17,  1.27it/s]08:34<08:34, 257.14s/it]\n",
      "Classes:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [11:51<11:51, 355.77s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m combo \u001b[38;5;241m=\u001b[39m combo_names[(i \u001b[38;5;241m+\u001b[39m j) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mlen\u001b[39m(combo_names)]\n\u001b[1;32m     34\u001b[0m steps \u001b[38;5;241m=\u001b[39m AUGMENTATION_COMBINATIONS[combo]\n\u001b[0;32m---> 36\u001b[0m y_aug \u001b[38;5;241m=\u001b[39m \u001b[43maugment_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m filename_aug \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_path\u001b[38;5;241m.\u001b[39mstem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcombo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m output_path \u001b[38;5;241m=\u001b[39m AUGMENTED_TRAIN_AUDIOS_DIR \u001b[38;5;241m/\u001b[39m filename_aug\n",
      "Cell \u001b[0;32mIn[20], line 23\u001b[0m, in \u001b[0;36maugment_audio\u001b[0;34m(y, sr, steps)\u001b[0m\n\u001b[1;32m     21\u001b[0m     y_aug \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39meffects\u001b[38;5;241m.\u001b[39mtime_stretch(y_aug, rate\u001b[38;5;241m=\u001b[39mparam)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m aug_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpitch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 23\u001b[0m     y_aug \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffects\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpitch_shift\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_aug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m aug_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnoise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     25\u001b[0m     noise \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, param, \u001b[38;5;28mlen\u001b[39m(y_aug))\n",
      "File \u001b[0;32m~/codebase/senac-ia/neural-networks/rn-musical-insturments/.venv/lib/python3.9/site-packages/librosa/effects.py:478\u001b[0m, in \u001b[0;36mpitch_shift\u001b[0;34m(y, sr, n_steps, bins_per_octave, res_type, scale, **kwargs)\u001b[0m\n\u001b[1;32m    474\u001b[0m rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mfloat\u001b[39m(n_steps) \u001b[38;5;241m/\u001b[39m bins_per_octave)\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# Stretch in time, then resample\u001b[39;00m\n\u001b[1;32m    477\u001b[0m y_shift \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mresample(\n\u001b[0;32m--> 478\u001b[0m     \u001b[43mtime_stretch\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    479\u001b[0m     orig_sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(sr) \u001b[38;5;241m/\u001b[39m rate,\n\u001b[1;32m    480\u001b[0m     target_sr\u001b[38;5;241m=\u001b[39msr,\n\u001b[1;32m    481\u001b[0m     res_type\u001b[38;5;241m=\u001b[39mres_type,\n\u001b[1;32m    482\u001b[0m     scale\u001b[38;5;241m=\u001b[39mscale,\n\u001b[1;32m    483\u001b[0m )\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# Crop to the same dimension as the input\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m util\u001b[38;5;241m.\u001b[39mfix_length(y_shift, size\u001b[38;5;241m=\u001b[39my\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/codebase/senac-ia/neural-networks/rn-musical-insturments/.venv/lib/python3.9/site-packages/librosa/effects.py:383\u001b[0m, in \u001b[0;36mtime_stretch\u001b[0;34m(y, rate, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m stft \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mstft(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# Stretch by phase vocoding\u001b[39;00m\n\u001b[0;32m--> 383\u001b[0m stft_stretch \u001b[38;5;241m=\u001b[39m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphase_vocoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhop_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_fft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;66;03m# Predict the length of y_stretch\u001b[39;00m\n\u001b[1;32m    391\u001b[0m len_stretch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mround\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m rate))\n",
      "File \u001b[0;32m~/codebase/senac-ia/neural-networks/rn-musical-insturments/.venv/lib/python3.9/site-packages/librosa/core/spectrum.py:1462\u001b[0m, in \u001b[0;36mphase_vocoder\u001b[0;34m(D, rate, hop_length, n_fft)\u001b[0m\n\u001b[1;32m   1459\u001b[0m mag \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m alpha) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(columns[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m alpha \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(columns[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m   1461\u001b[0m \u001b[38;5;66;03m# Store to output array\u001b[39;00m\n\u001b[0;32m-> 1462\u001b[0m d_stretch[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, t] \u001b[38;5;241m=\u001b[39m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphasor\u001b[49m(phase_acc, mag\u001b[38;5;241m=\u001b[39mmag)\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;66;03m# Compute phase advance\u001b[39;00m\n\u001b[1;32m   1465\u001b[0m dphase \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mangle(columns[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mangle(columns[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m-\u001b[39m phi_advance\n",
      "File \u001b[0;32m~/codebase/senac-ia/neural-networks/rn-musical-insturments/.venv/lib/python3.9/site-packages/lazy_loader/__init__.py:77\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     71\u001b[0m attr_to_modules \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     72\u001b[0m     attr: mod \u001b[38;5;28;01mfor\u001b[39;00m mod, attrs \u001b[38;5;129;01min\u001b[39;00m submod_attrs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m attrs\n\u001b[1;32m     73\u001b[0m }\n\u001b[1;32m     75\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(submodules \u001b[38;5;241m|\u001b[39m attr_to_modules\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(name):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m submodules:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_train = pd.read_csv(NORMALIZED_TRAIN_CSV_PATH)\n",
    "grouped = df_train.groupby(\"class\")\n",
    "\n",
    "augmented_train_records = []\n",
    "\n",
    "\n",
    "for class_name, group in tqdm(df_train.groupby(\"class\"), desc=\"Augmentando treino\"):\n",
    "    combo_names = list(AUGMENTATION_COMBINATIONS.keys())\n",
    "    combo_names.remove(\"original\")\n",
    "\n",
    "    for i, row in group.reset_index(drop=True).iterrows():\n",
    "        original_path = NORMALIZED_TRAIN_AUDIOS_DIR / row[\"filename\"]\n",
    "        if not original_path.exists():\n",
    "            continue\n",
    "\n",
    "        y, sr = librosa.load(original_path, sr=SAMPLE_RATE)\n",
    "\n",
    "        original_filename = f\"{original_path.stem}__original.wav\"\n",
    "        output_original_path = AUGMENTED_TRAIN_AUDIOS_DIR / original_filename\n",
    "        sf.write(output_original_path, y, sr, format=\"WAV\")\n",
    "        augmented_train_records.append({\n",
    "            \"file_name\": original_filename,\n",
    "            \"class\": class_name,\n",
    "            \"augmentation\": \"original\"\n",
    "        })\n",
    "\n",
    "        for j in range(MAX_AUGS_PER_ORIGINAL):\n",
    "            combo = combo_names[j % len(combo_names)]\n",
    "            steps = AUGMENTATION_COMBINATIONS[combo]\n",
    "\n",
    "            y_aug = augment_audio(y, sr, steps)\n",
    "            filename_aug = f\"{original_path.stem}__{combo}.wav\"\n",
    "            output_path = AUGMENTED_TRAIN_AUDIOS_DIR / filename_aug\n",
    "\n",
    "            sf.write(output_path, y_aug, sr, format=\"WAV\")\n",
    "            augmented_train_records.append({\n",
    "                \"file_name\": filename_aug,\n",
    "                \"class\": class_name,\n",
    "                \"augmentation\": combo\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1883cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_augmented_train = pd.DataFrame(augmented_train_records)\n",
    "df_augmedf_augmented_trainnted.to_csv(AUGMENTED_TRAIN_CSV_PATH, index=False)\n",
    "\n",
    "print(f\"üìÑ CSV de metadados salvo em: {AUGMENTED_TRAIN_CSV_PATH}\")\n",
    "print(f\"üéß Total de arquivos augmentados: {len(df_augmented_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255cc6d7",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eb973c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Vers√£o v1: ../datasets/prepared/v1\n",
      "üìÅ Cortes de treino ser√£o salvos em: ../datasets/prepared/v1/train_data\n",
      "üìÅ Cortes de teste ser√£o salvos em: ../datasets/prepared/v1/train_data\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "WINDOW_SIZE = 3.0    # segundos\n",
    "OVERLAP = 1.5        # segundos\n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "PREPARATION_VERSION = \"v1\"\n",
    "AUGMENTATION_VERSION_SOURCE = \"v1\"\n",
    "\n",
    "# Diret√≥rios base\n",
    "PREPARED_DATASET_VERSION_PATH = Path(os.path.join(PREPARED_DATASET_PATH, PREPARATION_VERSION))\n",
    "PREPARED_DATASET_VERSION_PATH.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"üìÅ Vers√£o {PREPARATION_VERSION}: {PREPARED_DATASET_VERSION_PATH}\")\n",
    "\n",
    "PREPARED_TRAIN_AUDIOS_DIR = Path(os.path.join(PREPARED_DATASET_VERSION_PATH, 'train_data'))\n",
    "PREPARED_TRAIN_AUDIOS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"üìÅ Cortes de treino ser√£o salvos em: {PREPARED_TRAIN_AUDIOS_DIR}\")\n",
    "\n",
    "PREPARED_TEST_AUDIOS_DIR = Path(os.path.join(PREPARED_DATASET_VERSION_PATH, 'test_data'))\n",
    "PREPARED_TEST_AUDIOS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"üìÅ Cortes de teste ser√£o salvos em: {PREPARED_TRAIN_AUDIOS_DIR}\")\n",
    "\n",
    "AUGMENTED_PREPARE_DATASET_VERSION_PATH = Path(os.path.join(AUGMENTED_DATASET_PATH, AUGMENTATION_VERSION_SOURCE))\n",
    "\n",
    "\n",
    "AUGMENTED_PREPARE_TEST_AUDIOS_DIR = Path(os.path.join(AUGMENTED_DATASET_VERSION_PATH, 'test_data'))\n",
    "AUGMENTED_PREPARE_TEST_CSV_PATH = AUGMENTED_PREPARE_DATASET_VERSION_PATH / \"test_metadata.csv\"\n",
    "\n",
    "AUGMENTED_PREPARE_TRAIN_AUDIOS_DIR = Path(os.path.join(AUGMENTED_DATASET_VERSION_PATH, 'train_data'))\n",
    "AUGMENTED_PREPARE_TRAIN_CSV_PATH = AUGMENTED_PREPARE_DATASET_VERSION_PATH / \"train_metadata.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "614c51fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_audio_with_overlap(file_path: Path, class_name: str, output_dir: Path, \n",
    "                             window_size: float, overlap: float, sample_rate: int = 22050):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=sample_rate)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao carregar {file_path.name}: {e}\")\n",
    "        return []\n",
    "\n",
    "    window_samples = int(window_size * sr)\n",
    "    hop_samples = int((window_size - overlap) * sr)\n",
    "\n",
    "    segments = []\n",
    "    base_name = file_path.stem  # Nome base sem extens√£o\n",
    "\n",
    "    for i, start in enumerate(range(0, len(y), hop_samples)):\n",
    "        end = start + window_samples\n",
    "        slice_audio = y[start:end]\n",
    "\n",
    "        # Padding com zeros se for menor que o necess√°rio\n",
    "        if len(slice_audio) < window_samples:\n",
    "            slice_audio = np.pad(slice_audio, (0, window_samples - len(slice_audio)))\n",
    "\n",
    "        # Gera nome padronizado com extens√£o .wav\n",
    "        filename_seq = f\"{base_name}_{i+1:06}.wav\"\n",
    "        out_path = output_dir / filename_seq\n",
    "\n",
    "        try:\n",
    "            sf.write(out_path, slice_audio, sr, format='WAV')\n",
    "            segments.append((filename_seq, class_name))\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro ao salvar {out_path.name}: {e}\")\n",
    "\n",
    "        if end >= len(y):\n",
    "            break\n",
    "\n",
    "    return segments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c6e19d",
   "metadata": {},
   "source": [
    "#### Prepare test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a78d7af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [00:06<00:00, 12.18it/s]\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(NORMALIZED_TEST_CSV_PATH)\n",
    "\n",
    "prepared_test_data = []\n",
    "\n",
    "for _, row in tqdm(df_test.iterrows(), total=len(df_test)):\n",
    "    original_path = NORMALIZED_TEST_AUDIOS_DIR / row[\"filename\"]\n",
    "    class_name = row[\"class\"]\n",
    "\n",
    "    if original_path.exists():\n",
    "        segments = slice_audio_with_overlap(\n",
    "            file_path=original_path,\n",
    "            class_name=class_name,\n",
    "            output_dir=PREPARED_TEST_AUDIOS_DIR,\n",
    "            window_size=WINDOW_SIZE,\n",
    "            overlap=OVERLAP,\n",
    "            sample_rate=SAMPLE_RATE\n",
    "        )\n",
    "        prepared_test_data.extend(segments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "008508c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Metadata de teste salva em: ../datasets/prepared/v1/test_metadata.csv\n",
      "üéß Total de segmentos: 1238\n"
     ]
    }
   ],
   "source": [
    "df_prepared_test = pd.DataFrame(prepared_test_data, columns=[\"filename\", \"class\"])\n",
    "\n",
    "PREPARED_TEST_CSV_PATH = PREPARED_DATASET_VERSION_PATH / \"test_metadata.csv\"\n",
    "df_prepared_test.to_csv(PREPARED_TEST_CSV_PATH, index=False)\n",
    "\n",
    "print(f\"üìÑ Metadata de teste salva em: {PREPARED_TEST_CSV_PATH}\")\n",
    "print(f\"üéß Total de segmentos: {len(df_prepared_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc2b1eb",
   "metadata": {},
   "source": [
    "#### Prepare train files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "640a61b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2629/2629 [02:51<00:00, 15.30it/s]\n"
     ]
    }
   ],
   "source": [
    "prepared_train_data = []\n",
    "\n",
    "for _, row in tqdm(df_train.iterrows(), total=len(df_train)):\n",
    "    original_path = NORMALIZED_TRAIN_AUDIOS_DIR / row[\"filename\"]\n",
    "    class_name = row[\"class\"]\n",
    "\n",
    "    if original_path.exists():\n",
    "        segments = slice_audio_with_overlap(\n",
    "            file_path=original_path,\n",
    "            class_name=class_name,\n",
    "            output_dir=PREPARED_TRAIN_AUDIOS_DIR,\n",
    "            window_size=WINDOW_SIZE,\n",
    "            overlap=OVERLAP,\n",
    "            sample_rate=SAMPLE_RATE\n",
    "        )\n",
    "        prepared_train_data.extend(segments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fadd8042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Metadata de treino salva em: ../datasets/prepared/v1/train_prepared_metadata.csv\n",
      "üéß Total de segmentos: 29893\n"
     ]
    }
   ],
   "source": [
    "df_prepared_train = pd.DataFrame(prepared_train_data, columns=[\"file_name\", \"class\"])\n",
    "\n",
    "PREPARED_TRAIN_CSV_PATH = PREPARED_DATASET_VERSION_PATH / \"train_prepared_metadata.csv\"\n",
    "df_prepared_train.to_csv(PREPARED_TRAIN_CSV_PATH, index=False)\n",
    "\n",
    "print(f\"üìÑ Metadata de treino salva em: {PREPARED_TRAIN_CSV_PATH}\")\n",
    "print(f\"üéß Total de segmentos: {len(df_prepared_train)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
